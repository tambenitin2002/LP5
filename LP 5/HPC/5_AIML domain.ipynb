{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpi4py import MPI\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data for demonstration\n",
    "def generate_data(num_samples, input_shape):\n",
    "    return np.random.rand(num_samples, *input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple convolutional neural network model\n",
    "def build_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model using parallel processing\n",
    "def train_model(train_data, train_labels, epochs=10, batch_size=32):\n",
    "    input_shape = train_data.shape[1:]\n",
    "    num_classes = train_labels.shape[1]\n",
    "\n",
    "    model = build_model(input_shape, num_classes)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    # Split data across processes\n",
    "    data_per_process = len(train_data) // size\n",
    "    start_index = rank * data_per_process\n",
    "    end_index = start_index + data_per_process\n",
    "    train_data_process = train_data[start_index:end_index]\n",
    "    train_labels_process = train_labels[start_index:end_index]\n",
    "  # Train the model\n",
    "    model.fit(train_data_process, train_labels_process, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32/32 [==============================] - 9s 125ms/step - loss: 2340.4375 - accuracy: 0.0730\n",
      "Epoch 2/10\n",
      "32/32 [==============================] - 3s 96ms/step - loss: 141901.4531 - accuracy: 0.0770\n",
      "Epoch 3/10\n",
      "32/32 [==============================] - 3s 94ms/step - loss: 1824427.0000 - accuracy: 0.0770\n",
      "Epoch 4/10\n",
      "32/32 [==============================] - 3s 106ms/step - loss: 11040781.0000 - accuracy: 0.0770\n",
      "Epoch 5/10\n",
      "32/32 [==============================] - 3s 98ms/step - loss: 42331112.0000 - accuracy: 0.0770\n",
      "Epoch 6/10\n",
      "32/32 [==============================] - 3s 102ms/step - loss: 121947968.0000 - accuracy: 0.0770\n",
      "Epoch 7/10\n",
      "32/32 [==============================] - 4s 110ms/step - loss: 288911936.0000 - accuracy: 0.0770\n",
      "Epoch 8/10\n",
      "32/32 [==============================] - 4s 114ms/step - loss: 592595968.0000 - accuracy: 0.0770\n",
      "Epoch 9/10\n",
      "32/32 [==============================] - 4s 115ms/step - loss: 1096832000.0000 - accuracy: 0.0770\n",
      "Epoch 10/10\n",
      "32/32 [==============================] - 4s 141ms/step - loss: 1880731904.0000 - accuracy: 0.0770\n",
      "4/4 [==============================] - 3s 36ms/step - loss: 2442109696.0000 - accuracy: 0.1000\n",
      "Process 0: Test loss: 2442109696.0, Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    " if __name__ == '__main__':\n",
    "    # Generate synthetic data\n",
    "    num_samples = 1000\n",
    "    input_shape = (28, 28, 1)  # Example image shape\n",
    "    num_classes = 10  # Example number of classes\n",
    "    train_data = generate_data(num_samples, input_shape)\n",
    "    train_labels = np.random.randint(0, num_classes, size=(num_samples, num_classes))\n",
    "\n",
    "    # Train the model\n",
    "    trained_model = train_model(train_data, train_labels)\n",
    "\n",
    "    # Evaluate the model (each process can evaluate its own portion of data)\n",
    "    test_data = generate_data(100, input_shape)\n",
    "    test_labels = np.random.randint(0, num_classes, size=(100, num_classes))\n",
    "    loss, accuracy = trained_model.evaluate(test_data, test_labels)\n",
    "    print(f'Process {rank}: Test loss: {loss}, Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
